{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2\n",
    "\n",
    "Change the architecture of your DNN using convolutional layers. Use `Conv2D`, `MaxPooling2D`, `Dropout`, but also do not forget `Flatten`, a standard `Dense` layer and `soft-max` in the end. I have merged step 2 and 3 in the following definition of `create_CNN()` that **<span style=\"color:red\">you should complete</span>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 18:49:16.081775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "seed = 0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "labels = np.array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many columns as there are classes.\n",
    "# The number of rows stays the same.\n",
    "keras.utils.to_categorical(labels) # transform the array of labels into a matrix with as many columns as there are classes\n",
    "# It's not binary, it's an encoding of the labels (categorical) for the cross-entropy loss function \n",
    "\n",
    "# reshape data, it could depend on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols) # reshape input image to a vector\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "\n",
    "# cast to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1] (normalize)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Convolutional Neural Nets with Keras\n",
    "\n",
    "We have so far considered each MNIST data sample as a $(28\\times 28,)$-long 1d vector. On the other hand, we do know that in every one of the hand-written digits there are *local* spatial correlations between the pixels, but also *translational invariance*, which we would like to take advantage of to improve the accuracy of our classification model. To this end, we first need to reshape the training and test input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #\n",
    "    # ADD HERE SOME OTHER LAYERS AT YOUR WILL, FOR EXAMPLE SOME: Dropout, 2D pooling, 2D convolutional etc. ... \n",
    "    # remember to move towards a standard flat layer in the final part of your DNN,\n",
    "    # and that we need a soft-max layer with num_classes=10 possible outputs\n",
    "      # Add a second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5), activation='relu'))\n",
    "    \n",
    "    # Add a max-pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add a dropout layer for regularization\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Add a third convolutional layer with 50 filters\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "    # Add another max-pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Add another dropout layer\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten the layers to transition from 2D to 1D\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add a fully connected layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Add another dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Add the final output layer with softmax activation\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your DCNN and evaluate its performance proceeding exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.8601 - acc: 0.7074 - val_loss: 0.1602 - val_acc: 0.9546\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2613 - acc: 0.9196 - val_loss: 0.1010 - val_acc: 0.9688\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1973 - acc: 0.9402 - val_loss: 0.0763 - val_acc: 0.9764\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1653 - acc: 0.9495 - val_loss: 0.0641 - val_acc: 0.9796\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1451 - acc: 0.9565 - val_loss: 0.0567 - val_acc: 0.9820\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1297 - acc: 0.9611 - val_loss: 0.0510 - val_acc: 0.9840\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1183 - acc: 0.9650 - val_loss: 0.0460 - val_acc: 0.9847\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1107 - acc: 0.9668 - val_loss: 0.0433 - val_acc: 0.9866\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1030 - acc: 0.9698 - val_loss: 0.0441 - val_acc: 0.9859\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0969 - acc: 0.9708 - val_loss: 0.0381 - val_acc: 0.9887\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0927 - acc: 0.9724 - val_loss: 0.0374 - val_acc: 0.9880\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0891 - acc: 0.9732 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0839 - acc: 0.9743 - val_loss: 0.0329 - val_acc: 0.9892\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0790 - acc: 0.9772 - val_loss: 0.0317 - val_acc: 0.9892\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0758 - acc: 0.9769 - val_loss: 0.0315 - val_acc: 0.9888\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0725 - acc: 0.9780 - val_loss: 0.0305 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0725 - acc: 0.9783 - val_loss: 0.0296 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0698 - acc: 0.9789 - val_loss: 0.0283 - val_acc: 0.9906\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0697 - acc: 0.9787 - val_loss: 0.0279 - val_acc: 0.9911\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0656 - acc: 0.9799 - val_loss: 0.0279 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0621 - acc: 0.9811 - val_loss: 0.0258 - val_acc: 0.9915\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0634 - acc: 0.9810 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0628 - acc: 0.9817 - val_loss: 0.0265 - val_acc: 0.9920\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0586 - acc: 0.9824 - val_loss: 0.0246 - val_acc: 0.9927\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0581 - acc: 0.9833 - val_loss: 0.0251 - val_acc: 0.9918\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0569 - acc: 0.9827 - val_loss: 0.0247 - val_acc: 0.9917\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0576 - acc: 0.9831 - val_loss: 0.0239 - val_acc: 0.9923\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0541 - acc: 0.9836 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0535 - acc: 0.9836 - val_loss: 0.0221 - val_acc: 0.9925\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0536 - acc: 0.9836 - val_loss: 0.0232 - val_acc: 0.9916\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0505 - acc: 0.9848 - val_loss: 0.0243 - val_acc: 0.9925\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0508 - acc: 0.9844 - val_loss: 0.0217 - val_acc: 0.9926\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0504 - acc: 0.9841 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0486 - acc: 0.9851 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0482 - acc: 0.9851 - val_loss: 0.0211 - val_acc: 0.9927\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0469 - acc: 0.9852 - val_loss: 0.0201 - val_acc: 0.9934\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0475 - acc: 0.9858 - val_loss: 0.0206 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 0.0213 - val_acc: 0.9931\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0446 - acc: 0.9862 - val_loss: 0.0195 - val_acc: 0.9940\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0449 - acc: 0.9862 - val_loss: 0.0203 - val_acc: 0.9935\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0459 - acc: 0.9857 - val_loss: 0.0201 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0422 - acc: 0.9870 - val_loss: 0.0202 - val_acc: 0.9931\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0439 - acc: 0.9867 - val_loss: 0.0195 - val_acc: 0.9940\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.0194 - val_acc: 0.9942\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0433 - acc: 0.9869 - val_loss: 0.0188 - val_acc: 0.9947\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0423 - acc: 0.9868 - val_loss: 0.0200 - val_acc: 0.9936\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0411 - acc: 0.9874 - val_loss: 0.0189 - val_acc: 0.9936\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0412 - acc: 0.9875 - val_loss: 0.0183 - val_acc: 0.9941\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0408 - acc: 0.9872 - val_loss: 0.0193 - val_acc: 0.9933\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0406 - acc: 0.9873 - val_loss: 0.0188 - val_acc: 0.9934\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0188 - acc: 0.9934\n",
      "\n",
      "Test loss: 0.018773715943098068\n",
      "Test accuracy: 0.993399977684021\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "history = model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and history\n",
    "# UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. \n",
    "# We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
    "model_CNN.save('DATA/models/CNN/model_CNN1.keras')\n",
    "# print data to file\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "data = {\n",
    "    'epoch': epochs,\n",
    "    'loss': history.history['loss'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'acc': history.history['acc'],\n",
    "    'val_acc': history.history['val_acc']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f'DATA/DCNN.dat', index=False, sep = ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
